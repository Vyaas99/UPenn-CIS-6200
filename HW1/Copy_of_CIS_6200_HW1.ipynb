{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CIS 6200 Spring 2024 Homework 1**\n",
        "\n",
        "\n",
        "Objective:\n",
        "*   Implement context Chunking\n",
        "*   Learn about Longformer and how it works\n",
        "\n",
        "\n",
        "Tasks:\n",
        "\n",
        "*  Complete the **Context Chunking** section of this notebook by filling out the code. Experiment with different hyperparameters and answer the question at the end of the section in PDF.\n",
        "  * Question 1: Explain Chunking in a few sentences.\n",
        "  * Question 2: Why does chunking fail in the later example? Can you give another example on which chunking also fails?\n",
        "*  Answer the questions about **LongFormer** and complete the second section. Report your results and compare with results from chunking.\n",
        "  * Question 3: Read the [Longformer paper](https://arxiv.org/abs/2004.05150).\n",
        "    * What is the Sliding Window Attention and Global Attention for Longformer?\n",
        "    * How do they capture information in a long context?\n",
        "  * Question 4: Read about the [\"Lost in the Middle\"](https://arxiv.org/abs/2307.03172) phenomena of LLMs.\n",
        "    * What is the phenomena describing? What might be a reason for it to happen?\n",
        "    * Based on your understanding of Longformer, will it also suffer the same problem? **(Answer in PDF)\n",
        "\n",
        "**Note: Answers to the task questions need to be submitted in the corresponding PDF submission along with this coding submission on gradescope.**"
      ],
      "metadata": {
        "id": "le3O5w58dm_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "7Ius8JiXKlNr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kyLwyD9VlG8H"
      },
      "outputs": [],
      "source": [
        "!pip -q install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VpMEsYRSfZCK"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "from transformers import LongformerTokenizer, LongformerForQuestionAnswering, AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wikipedia.page(\"University of Pennsylvania\").summary"
      ],
      "metadata": {
        "id": "LxBaXAnHuSwR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "0f1945d8-d25b-44e4-df42-7b7d938faa63"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The University of Pennsylvania (Penn or UPenn) is a private Ivy League research university in Philadelphia, Pennsylvania. It is one of nine colonial colleges and was chartered prior to the U.S. Declaration of Independence when Benjamin Franklin, the university's founder and first president, advocated for an educational institution that trained leaders in academia, commerce, and public service. Penn identifies as the fourth oldest institution of higher education in the United States, though this representation is challenged by other universities, as Franklin first convened the board of trustees in 1749, arguably making it the fifth oldest institution of higher education in the U.S.The university has four undergraduate schools and 12 graduate and professional schools. Schools enrolling undergraduates include the College of Arts and Sciences, the School of Engineering and Applied Science, the Wharton School, and the School of Nursing. Among its highly ranked graduate schools are its law school, whose first professor James Wilson participated in writing the first draft of the U.S. Constitution, its medical school, which was the first medical school established in North America, and Wharton, the nation's first collegiate business school. Penn's endowment is $20.7 billion, making it the sixth-wealthiest private academic institution in the nation as of 2022. In 2021, it ranked 4th among American universities in research expenditures according to the National Science Foundation.The University of Pennsylvania's main campus is located in the University City neighborhood of West Philadelphia, and is centered around College Hall. Notable campus landmarks include Houston Hall, the first modern student union, and Franklin Field, the nation's first dual-level college football stadium and the nation's longest-standing NCAA Division I college football stadium in continuous operation. The university's athletics program, the Penn Quakers, fields varsity teams in 33 sports as a member of NCAA Division I's Ivy League conference.\\nSince its founding, Penn alumni, trustees, and faculty have included 8 signers of the U.S. Declaration of Independence, 7 signers of the Constitution, 3 Presidents of the United States, 3 U.S. Supreme Court justices, 32 U.S. senators, 163 members of the U.S. House of Representatives, 19 U.S. Cabinet Secretaries, 46 governors, 28 State Supreme Court justices, and 9 foreign heads of state. Alumni and faculty include 39 Nobel laureates, 4 Turing Award winners, and a Fields Medalist. Penn has graduated 32 Rhodes Scholars and 21 Marshall Scholars. As of 2022, Penn has the largest number of undergraduate alumni who are billionaires of all colleges and universities (17, counting only Penn's four undergraduate schools). Penn alumni have won (a) 53 Tony Awards, (b) 17 Grammy Awards, (c) 25 Emmy Awards, and (d) 13 Academy Awards. At least 43 different Penn alumni have earned 81 Olympic medals (26 gold), 2 Penn alumni have been NASA astronauts, and 5 Penn alumni have been awarded the Medal of Honor.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A piece of longer information collected by querying wikipedia.page(\"University of Pennsylvania\").content\n",
        "\n",
        "wiki_info = \"\"\"\n",
        "The University of Pennsylvania (Penn or UPenn) is a private Ivy League research university in Philadelphia, Pennsylvania. It is one of nine colonial colleges and was chartered prior to the U.S. Declaration of Independence when Benjamin Franklin, the university's founder and first president, advocated for an educational institution that trained leaders in academia, commerce, and public service. Penn identifies as the fourth oldest institution of higher education in the United States, though this representation is challenged by other universities, as Franklin first convened the board of trustees in 1749, arguably making it the fifth oldest institution of higher education in the U.S.The university has four undergraduate schools and 12 graduate and professional schools. Schools enrolling undergraduates include the College of Arts and Sciences, the School of Engineering and Applied Science, the Wharton School, and the School of Nursing. Among its highly ranked graduate schools are its law school, whose first professor James Wilson participated in writing the first draft of the U.S. Constitution, its medical school, which was the first medical school established in North America, and Wharton, the nation's first collegiate business school. Penn's endowment is $20.7 billion, making it the sixth-wealthiest private academic institution in the nation as of 2022. In 2021, it ranked 4th among American universities in research expenditures according to the National Science Foundation.The University of Pennsylvania's main campus is located in the University City neighborhood of West Philadelphia, and is centered around College Hall. Notable campus landmarks include Houston Hall, the first modern student union, and Franklin Field, the nation's first dual-level college football stadium and the nation's longest-standing NCAA Division I college football stadium in continuous operation. The university's athletics program, the Penn Quakers, fields varsity teams in 33 sports as a member of NCAA Division I's Ivy League conference.\n",
        "Since its founding, Penn alumni, trustees, and faculty have included 8 signers of the U.S. Declaration of Independence, 7 signers of the Constitution, 3 Presidents of the United States, 3 U.S. Supreme Court justices, 32 U.S. senators, 163 members of the U.S. House of Representatives, 19 U.S. Cabinet Secretaries, 46 governors, 28 State Supreme Court justices, and 9 foreign heads of state. Alumni and faculty include 39 Nobel laureates, 4 Turing Award winners, and a Fields Medalist. Penn has graduated 32 Rhodes Scholars and 21 Marshall Scholars. As of 2022, Penn has the largest number of undergraduate alumni who are billionaires of all colleges and universities (17, counting only Penn's four undergraduate schools). Penn alumni have won (a) 53 Tony Awards, (b) 17 Grammy Awards, (c) 25 Emmy Awards, and (d) 13 Academy Awards. At least 43 different Penn alumni have earned 81 Olympic medals (26 gold), 2 Penn alumni have been NASA astronauts, and 5 Penn alumni have been awarded the Medal of Honor.\n",
        "\n",
        "Since the Penn Museum was founded in 1887, it has taken part in 400 research projects worldwide. The museum's first project was an excavation of Nippur, a location in current day Iraq.Penn Museum is home to the largest authentic sphinx in North America at about seven feet high, four feet wide, 13 feet long, and 12.9 tons (made of solid red granite).\n",
        "The sphinx was discovered in 1912 by the British archeologist, Sir William Matthew Flinders Petrie, during an excavation of the ancient Egyptian city of Memphis, Egypt, where the sphinx had guarded a temple to ward off evil. Since Petri's expedition was partially financed by Penn Petrie offered it to Penn, which arranged for it to be moved to museum in 1913. The sphinx was moved in 2019 to a more prominent spot intended to attract visitors.The museum has three gallery floors with artifacts from Egypt, the Middle East, Mesoamerica, Asia, the Mediterranean, Africa and indigenous artifacts of the Americas. Its most famous object is the goat rearing into the branches of a rosette-leafed plant, from the royal tombs of Ur.\n",
        "The Penn Museum's excavations and collections foster a strong research base for graduate students in the Graduate Group in the Art and Archaeology of the Mediterranean World. Features of the Beaux-Arts building include a rotunda and gardens that include Egyptian papyrus.\n",
        "\n",
        "Penn's educational innovations include the nation's first medical school in 1765; the first university teaching hospital in 1874; the Wharton School, the world's first collegiate business school, in 1881; the first American student union building, Houston Hall, in 1896; the only school of veterinary medicine in the United States that originated directly from its medical school, in 1884; and the home of ENIAC, the world's first electronic, large-scale, general-purpose digital computer in 1946. Penn is also home to the oldest continuously functioning psychology department in North America and is where the American Medical Association was founded. In 1921, Penn was also the first university to award a PhD in economics to an African American woman, Sadie Tanner Mossell Alexander.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PvOxgURBClG3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context Chunking"
      ],
      "metadata": {
        "id": "7yiG-IcuIO67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1:** \\\n",
        "Explain Chunking in a few sentences. **(Answer in PDF)**\n",
        "\n",
        "You can use [LangChain](https://python.langchain.com/docs/modules/data_connection/document_transformers/#evaluate-text-splitters) for a reference."
      ],
      "metadata": {
        "id": "4IYs94R5OvWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Implementation**"
      ],
      "metadata": {
        "id": "kkIQGu7lPlae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Setup model \"distilbert-base-cased-distilled-squad\"\n",
        "\n",
        "checkpoint=\"distilbert-base-cased-distilled-squad\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "pK5zmMrqOmbR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_with_chunks(text, question, chunk_size=256):\n",
        "\n",
        "    # TODO: Tokenize question and context\n",
        "    question_tokens = tokenizer.encode(question)\n",
        "    context_tokens = tokenizer.encode(text)\n",
        "\n",
        "    # TODO: Chunk the context according to chuck_size\n",
        "    chunks = [context_tokens[i:i + chunk_size] for i in range(0, len(context_tokens), chunk_size)]\n",
        "\n",
        "    # Run the model on each chuck to get outputs\n",
        "    all_answers = []\n",
        "    all_scores = []\n",
        "    for chunk in chunks:\n",
        "\n",
        "        # Prepare input tokens. Note: [CLS] and [SEP] are BERT tokens, to learn more: https://datascience.stackexchange.com/questions/51522/what-is-the-use-of-sep-in-paper-bert\n",
        "        input_tokens = ['[CLS]'] + question_tokens + ['[SEP]'] + chunk + ['[SEP]']\n",
        "\n",
        "        #Prepare input tokens\n",
        "        input_ids=tokenizer.build_inputs_with_special_tokens(question_tokens, chunk)\n",
        "\n",
        "        #Convert to PyTorch tensors\n",
        "        input_ids_tensor=torch.tensor([input_ids])\n",
        "\n",
        "        outputs=model(input_ids_tensor)\n",
        "        answer_start_scores=outputs.start_logits\n",
        "        answer_end_scores=outputs.end_logits\n",
        "\n",
        "        answer_start = torch.argmax(answer_start_scores)\n",
        "        answer_end = torch.argmax(answer_end_scores) + 1 #Adding 1 because the end index is exclusive\n",
        "\n",
        "        # Query the model for outputs, extract and decode the answer by selecting the best start / end logits\n",
        "        answer = tokenizer.decode(input_ids[answer_start:answer_end])\n",
        "        all_answers.append(answer)\n",
        "        scores = answer_start_scores[0, answer_start.item()] + answer_end_scores[0, answer_end.item()]\n",
        "        all_scores.append(scores)\n",
        "\n",
        "    # Get the most-likely right answer by taking the max of scores\n",
        "    best_answer = all_answers[torch.argmax(torch.tensor(all_scores))]\n",
        "\n",
        "    return all_answers, all_scores, best_answer"
      ],
      "metadata": {
        "id": "wPhdHsVPT1Oz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example that success with BERT\n",
        "text = wikipedia.page(\"University of Pennsylvania\").summary\n",
        "question = \"Where is upenn\"\n",
        "\n",
        "answers, scores, best_answer = process_with_chunks(text, question)\n",
        "print(\"All answers: \", answers, \"\\nAll scores: \", scores, \"\\nBest answer: \", best_answer)"
      ],
      "metadata": {
        "id": "OB6lg_k2T4_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eedc5aff-b11d-436d-8413-33057fb6b849"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All answers:  ['Philadelphia, Pennsylvania', '[CLS]', 'Penn'] \n",
            "All scores:  [tensor(11.5886, grad_fn=<AddBackward0>), tensor(-0.6043, grad_fn=<AddBackward0>), tensor(2.4190, grad_fn=<AddBackward0>)] \n",
            "Best answer:  Philadelphia, Pennsylvania\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example that fails with BERT\n",
        "text = wiki_info\n",
        "question = \"Where is Penn Museum\"\n",
        "\n",
        "answers, scores, best_answer = process_with_chunks(text, question)\n",
        "print(\"All answers: \", answers, \"\\nAll scores: \", scores, \"\\nBest answer: \", best_answer)"
      ],
      "metadata": {
        "id": "Bb2qLRR4EnL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b0ab24-0979-4deb-e209-0766c2e7c5e7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All answers:  ['Philadelphia, Pennsylvania', '[CLS]', '[CLS]', '', 'Penn Museum'] \n",
            "All scores:  [tensor(7.2992, grad_fn=<AddBackward0>), tensor(6.6112, grad_fn=<AddBackward0>), tensor(-4.1207, grad_fn=<AddBackward0>), tensor(-1.0483, grad_fn=<AddBackward0>), tensor(-6.9324, grad_fn=<AddBackward0>)] \n",
            "Best answer:  Philadelphia, Pennsylvania\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Own Example that fails with BERT\n",
        "text = wiki_info\n",
        "question = \"Where is Memphis located?\"#Correct answer is Egypt\n",
        "\n",
        "answers, scores, best_answer = process_with_chunks(text, question)\n",
        "print(\"All answers: \", answers, \"\\nAll scores: \", scores, \"\\nBest answer: \", best_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KNxTTwlymQI",
        "outputId": "d411abab-9569-4209-d7c6-3ca6a438f5bc"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All answers:  ['Philadelphia', 'West Philadelphia', 'Egypt', '[CLS]', 'Penn'] \n",
            "All scores:  [tensor(3.8445, grad_fn=<AddBackward0>), tensor(-2.0553, grad_fn=<AddBackward0>), tensor(1.2888, grad_fn=<AddBackward0>), tensor(-2.1990, grad_fn=<AddBackward0>), tensor(-10.9857, grad_fn=<AddBackward0>)] \n",
            "Best answer:  Philadelphia\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2:** \\\n",
        "Why does chunking fail in the later example? Can you give another example on which chunking also fails? **(Answer in PDF)**"
      ],
      "metadata": {
        "id": "Y7_We2l8Nb6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Longformer"
      ],
      "metadata": {
        "id": "37radmWPtplg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3** Read the [Longformer paper](https://arxiv.org/abs/2004.05150).\n",
        "  * What is the Sliding Window Attention and Global Attention for Longformer?\n",
        "  * How do they capture information in a long context? **(Answer in PDF)**"
      ],
      "metadata": {
        "id": "z9khhGhgP0WY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Implementation**"
      ],
      "metadata": {
        "id": "on80J5ikP5FV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ABxpquSvlvJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5db253fc-c73e-4dc1-a467-b2efb78e21e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at valhalla/longformer-base-4096-finetuned-squadv1 were not used when initializing LongformerForQuestionAnswering: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
            "- This IS expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# Initialize the models\n",
        "\n",
        "longformer_tokenizer = AutoTokenizer.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")\n",
        "longformer_model = AutoModelForQuestionAnswering.from_pretrained(\"valhalla/longformer-base-4096-finetuned-squadv1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_with_longformer(text, question):\n",
        "    # Tokenize the input text\n",
        "    encoding = longformer_tokenizer.encode_plus(question, text, return_tensors=\"pt\")\n",
        "    input_ids = encoding[\"input_ids\"]\n",
        "    attention_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "    # Get the predictions\n",
        "    outputs = longformer_model(input_ids, attention_mask=attention_mask)\n",
        "    start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
        "\n",
        "    # Convert predictions into answer\n",
        "    start_index = torch.argmax(start_scores)\n",
        "    end_index = torch.argmax(end_scores) + 1\n",
        "    answer = longformer_tokenizer.decode(input_ids[0, start_index:end_index], skip_special_tokens=True)\n",
        "\n",
        "    # Print answer\n",
        "    return(answer)"
      ],
      "metadata": {
        "id": "5OUTLkPq8tTf"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Success Example from section 1\n",
        "text = wikipedia.page(\"University of Pennsylvania\").summary\n",
        "question = \"Where is upenn\"\n",
        "\n",
        "\n",
        "answer = process_with_longformer(text, question)\n",
        "answer"
      ],
      "metadata": {
        "id": "zJFWjFcBHQoB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f2579710-b08c-4c9e-849d-766db4d60a27"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Philadelphia, Pennsylvania'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "rIzE9UhhgLJJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93e371af-681b-4643-c6bc-01be7a88d914"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Philadelphia, Pennsylvania'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# Failed Example from section 1 -- is it working now?\n",
        "text = wikipedia.page(\"University of Pennsylvania\").summary\n",
        "question = \"Where is Penn Museum\"\n",
        "\n",
        "\n",
        "answer = process_with_longformer(text, question)\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment with your other example from section 1 and verify it works\n",
        "\n",
        "text = wikipedia.page(\"University of Pennsylvania\").summary\n",
        "question = \"Where is Memphis located?\"#Correct answer is Egypt\n",
        "\n",
        "answer = process_with_longformer(text, question)\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cz3AnSZDlKzQ",
        "outputId": "52612be9-42c6-4b9e-a13f-51356b4fdf2f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Philadelphia, Pennsylvania'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4**\n",
        "Read about the [\"Lost in the Middle\"](https://arxiv.org/abs/2307.03172) phenomena of LLMs.\n",
        "* What is the phenomena describing? What might be a reason for it to happen?\n",
        "* Based on your understanding of Longformer, will it also suffer the same problem? **(Answer in PDF)**\n"
      ],
      "metadata": {
        "id": "_j68amI6IIe0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}